<!DOCTYPE html>
<html lang="en-US">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="../assets/css/just-the-docs-default.css">
    <script type="text/javascript" src="../assets/js/vendor/lunr.min.js"></script>
    <script type="text/javascript" src="../assets/js/just-the-docs.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>HW05 Quality Assurance | 17-313</title>
    <meta name="generator" content="Jekyll v3.9.0" />
    <meta property="og:title" content="HW05 Quality Assurance" />
    <meta name="author" content="Michael Hilton and Rohan Padye" />
    <meta property="og:locale" content="en_US" />
    <meta name="description" content="website for CMU 17-313" />
    <meta property="og:description" content="website for CMU 17-313" />
    <link rel="canonical" href="../assignments/hw5" />
    <meta property="og:url" content="http://localhost:4000/assignments/hw5" />
    <meta property="og:site_name" content="17-313" />
    <meta name="twitter:card" content="summary" />
    <meta property="twitter:title" content="HW05 Quality Assurance" />
    <script
        type="application/ld+json"> {"@type":"WebPage","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/17313_square.png"},"name":"Michael Hilton and Rohan Padye"},"headline":"HW05 Quality Assurance","url":"http://localhost:4000/assignments/hw5","author":{"@type":"Person","name":"Michael Hilton and Rohan Padye"},"description":"website for CMU 17-313","@context":"https://schema.org"}</script>

<body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
        <symbol id="svg-link" viewBox="0 0 24 24">
            <title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                class="feather feather-link">
                <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
                <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
            </svg>
        </symbol>
        <symbol id="svg-search" viewBox="0 0 24 24">
            <title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                class="feather feather-search">
                <circle cx="11" cy="11" r="8"></circle>
                <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
            </svg>
        </symbol>
        <symbol id="svg-menu" viewBox="0 0 24 24">
            <title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                class="feather feather-menu">
                <line x1="3" y1="12" x2="21" y2="12"></line>
                <line x1="3" y1="6" x2="21" y2="6"></line>
                <line x1="3" y1="18" x2="21" y2="18"></line>
            </svg>
        </symbol>
        <symbol id="svg-arrow-right" viewBox="0 0 24 24">
            <title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                class="feather feather-chevron-right">
                <polyline points="9 18 15 12 9 6"></polyline>
            </svg>
        </symbol>
        <symbol id="svg-doc" viewBox="0 0 24 24">
            <title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                class="feather feather-file">
                <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path>
                <polyline points="13 2 13 9 20 9"></polyline>
            </svg>
        </symbol>
    </svg>
    <div class="side-bar">
        <div class="site-header"> <a href="../" class="site-title lh-tight">
                <div class="site-logo"></div>
            </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon">
                    <use xlink:href="#svg-menu"></use>
                </svg> </a></div>
        <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
            <ul class="nav-list">
                <li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                            <use xlink:href="#svg-arrow-right"></use>
                        </svg></a><a href="../assignments/" class="nav-list-link">Assignments</a>
                    <ul class="nav-list ">
                        <li class="nav-list-item "><a href="../assignments/hw1" class="nav-list-link">HW01 Joining the
                                team</a>
                        <li class="nav-list-item "><a href="../assignments/hw2" class="nav-list-link">HW02 Teamwork</a>
                        <li class="nav-list-item "><a href="../assignments/hw3" class="nav-list-link">HW03
                                Requirements</a>
                        <li class="nav-list-item "><a href="../assignments/hw4" class="nav-list-link">HW04 ML
                                Microservices</a>
                        <li class="nav-list-item active"><a href="../assignments/hw5" class="nav-list-link active">HW05
                                Quality Assurance</a>
                        <li class="nav-list-item "><a href="../assignments/hw6" class="nav-list-link">HW06 Open Source
                                Excursion</a>
                    </ul>
                <li class="nav-list-item"><a href="../calendar/" class="nav-list-link">Calendar</a>
                <li class="nav-list-item"><a href="../schedule/" class="nav-list-link">Schedule</a>
                <li class="nav-list-item"><a href="../staff/" class="nav-list-link">Staff</a>
                <li class="nav-list-item"><a href="../syllabus/" class="nav-list-link">Syllabus</a>
            </ul>
        </nav>
        <footer class="site-footer"> This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the
                Docs</a>, a documentation theme for Jekyll.</footer>
    </div>
    <div class="main" id="top">
        <div id="main-header" class="main-header">
            <div class="search">
                <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0"
                        placeholder="Search 17-313" aria-label="Search 17-313" autocomplete="off"> <label
                        for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon">
                            <use xlink:href="#svg-search"></use>
                        </svg></label></div>
                <div id="search-results" class="search-results"></div>
            </div>
        </div>
        <div id="main-content-wrap" class="main-content-wrap">
            <nav aria-label="Breadcrumb" class="breadcrumb-nav">
                <ol class="breadcrumb-nav-list">
                    <li class="breadcrumb-nav-list-item"><a href="../assignments/">Assignments</a>
                    <li class="breadcrumb-nav-list-item"><span>HW05 Quality Assurance</span>
                </ol>
            </nav>
            <div id="main-content" class="main-content" role="main">
                <h1 id="17-313-foundations-of-software-engineering"> <a
                        href="#17-313-foundations-of-software-engineering" class="anchor-heading"
                        aria-labelledby="17-313-foundations-of-software-engineering"><svg viewBox="0 0 16 16"
                            aria-hidden="true">
                            <use xlink:href="#svg-link"></use>
                        </svg></a> 17-313: Foundations of Software Engineering</h1>
                <h2 id="homework-5-quality-assurance-for-the-people"> <a
                        href="#homework-5-quality-assurance-for-the-people" class="anchor-heading"
                        aria-labelledby="homework-5-quality-assurance-for-the-people"><svg viewBox="0 0 16 16"
                            aria-hidden="true">
                            <use xlink:href="#svg-link"></use>
                        </svg></a> Homework 5: Quality Assurance for the People</h2>
                <p>In this assignment, you will carefully consider and engage in several QA-related processes to
                    evaluate and look for defects in your prototype Mayan-EDMS-based graduate admissions system. The
                    goals of this assignment are:</p>
                <ul>
                    <li>
                        <p>Gain hands-on experience with analysis tools, including setting up, customizing, and using
                            them.</p>
                    <li>
                        <p>Practically assess and compare the costs and benefits of existing static and dynamic
                            bug-finding tools.</p>
                    <li>
                        <p>Develop a plan to integrate and roll out tools in development practice.</p>
                    <li>
                        <p>Explain the predictions of a Machine Learning Model, and reason about their implications.</p>
                </ul>
                <h3 id="project-context-and-tasks"> <a href="#project-context-and-tasks" class="anchor-heading"
                        aria-labelledby="project-context-and-tasks"><svg viewBox="0 0 16 16" aria-hidden="true">
                            <use xlink:href="#svg-link"></use>
                        </svg></a> Project Context and Tasks</h3>
                <p>Quality Assurance is a critical part of software development. Although you have been testing your new
                    graduate admissions system this whole time, you are now setting out to establish a sustained QA
                    practice that can be used moving forward as you iterate over and continue to improve your system.
                    Your CTO has assigned you the task of evaluating existing tools and practices beyond unit testing,
                    and producing a report on (A) the cost/benefit tradeoffs and risks of several tools and processes
                    and (B) how they might fit in development practice.</p>
                <h3 id="static-and-dynamic-analysis"> <a href="#static-and-dynamic-analysis" class="anchor-heading"
                        aria-labelledby="static-and-dynamic-analysis"><svg viewBox="0 0 16 16" aria-hidden="true">
                            <use xlink:href="#svg-link"></use>
                        </svg></a> Static and Dynamic Analysis</h3>
                <p>First, you will evaluate and choose between a set of analysis tools, integrate it into your
                    build/deployment pipeline, and document your decisions/process by way of a design document/RFC. For
                    the purposes of this RFC, you must identify and experiment with at least N potential static and
                    dynamic analysis tools that are applicable to your system, where N is the size of your group. We
                    provide a starter list below; you should include at least one static analysis and one dynamic
                    analysis tools, and at least one tool must be taken from either a Google search or from the Awesome
                    Static/Dynamic Analysis page (that is, cannot otherwise be listed in the bulleted list).</p>
                <p>You can create a new team repository by following the link for your team, which will clone the Mayan
                    EDMS code automatically:</p>
                <p><a href="https://classroom.github.com/a/Gj0UmUyt">Create Assignment with Github Classroom</a></p>
                <p>Apply one or more of the tools to your project. You may also apply it to one or more other programs
                    if you wish to assess it in different contexts. Consider and experiment with the types of
                    customization that are appropriate or necessary for this tool, both a priori (before they can be
                    used in your project) and possibly over time. Assess the strengths and weaknesses of each
                    tool/technique, both quantitatively and qualitatively. You might consider issues like, but not
                    limited to: what types of problems are you hoping your tooling will catch? What types of problems
                    does a particular tool catch? What types of customization are possible or necessary? How can/should
                    this tool be integrated into a development process? Are there many false positives? False negatives?
                    True positive reports about things you don’t care about?</p>
                <p>The deliverable for this part, at a high level, is a Design Document/RFC that explains and justifies
                    the tooling you propose to incorporate into your process, and how you propose to do so. This
                    decision should be feature- and data-driven, and should consider usability and process questions
                    like how and when the tooling will be applied, and by whom. See below for more details.</p>
                <p><strong>NOTE: you do not need to integrate ALL N tools into your repo, but you should integrate at
                        least (1) tool so that it runs via CI, and have one commit on which it was run. You should
                        reference this commit in your design document</strong></p>
                <p><strong>Starter list of Tools:</strong></p>
                <p>Static Analysis:</p>
                <ul>
                    <li>
                        <p><a href="https://www.pylint.org/">Pylint</a>, one of the best-known and most widely-used
                            Python static analysis suite, provides a collection of tools, including a linter/style
                            checker, pyreverse (which reverse-engineers UML diagrams), etc.</p>
                    <li>
                        <p><a href="https://pypi.org/project/pyflakes/">Pyflakes</a> is similar to the core linter in
                            pylint, but with an emphasis on speed and low false positives.</p>
                    <li>
                        <p><a href="http://www.mypy-lang.org/">Mypy</a> provides static type checking for Python</p>
                    <li>
                        <p><a href="https://www.sonarqube.org/features/multi-languages/">sonarQube</a> is a proprietary
                            product targeting multiple languages, including Python; it has an open-source version you
                            may want to try.</p>
                    <li>
                        <p><a href="http://flake8.pycqa.org/en/latest/">Flake8</a> provides a wrapper around a number of
                            other tools.</p>
                </ul>
                <p>Dynamic Analysis:</p>
                <ul>
                    <li>
                        <p><a href="https://docs.python.org/3/library/profile.html">The Python Profilers</a> provides
                            deterministic profiling of Python programs, which will provide you a set of statistics that
                            describes how often and for how long various parts of the program executed.</p>
                    <li>
                        <p><a href="https://coverage.readthedocs.io/en/6.1.1/#">Coverage.py</a> is a tool for measuring
                            code coverage of Python programs.</p>
                </ul>
                <p>Others are available. <a href="https://github.com/analysis-tools-dev/static-analysis">Awesome Static
                        Analysis page/repo</a> and <a
                        href="https://github.com/analysis-tools-dev/dynamic-analysis/">Awesome Dynamic Analysis
                        page/repo</a> have extensive listings of available static and dynamic analysis tools for a
                    pretty hefty list of programming languages, including Python. Other tools target Django
                    specifically; use your Googling skills, and see what you find!</p>
                <h3 id="ml-model-assessment"> <a href="#ml-model-assessment" class="anchor-heading"
                        aria-labelledby="ml-model-assessment"><svg viewBox="0 0 16 16" aria-hidden="true">
                            <use xlink:href="#svg-link"></use>
                        </svg></a> ML Model Assessment</h3>
                <p>In the last homework assignment, you created a Machine Learning model. In fact, after your success
                    with HW4, your team has started collecing data in production, and the new data for your ML service
                    goes well beyond the data you used for testing. Therefore, your CTO is seriously considering adding
                    it into your product.</p>
                <p>However, before announcing it as a feature, she wants to ensure that your team has a deep
                    understanding of how the ML model is working, as well as that it is tested with respect to any
                    concerns that may have surfaced previously.</p>
                <p>For this task, your team is tasked with writing a data-driven report for your CTO. You should
                    evaluate the model, test outcomes, present your findings, and discuss them.</p>
                <p>Your first task is to present a data-driven analysis of the predictions that your model is making.
                    You will do this using the LIME tool we have previously looked at in class: <a
                        href="https://github.com/marcotcr/lime">https://github.com/marcotcr/lime</a></p>
                <p>Run this tool on your model, and collect data on how the model is making predictions. You should use
                    this data to report on the behavior of the ML recommendation system.</p>
                <p>Here, when you run the tool, remember to use the more complete production data that your team has
                    collected, in the place of the previous limited training data. You can find the updated data here:
                    <a href="./ProductionData.csv.zip">Production Data</a></p>
                <p>The data-driven analysis will allow your company to ensure that the ML is working properly. However,
                    you are also concerned with fairness.</p>
                <p>You should also include in your report a data-driven analysis of the fairness of your algorithm. To
                    analyze the fairness, you should remember the fairness discussion we had in class, based on this
                    tool: <a href="https://research.google.com/bigpicture/attacking-discrimination-in-ml/">ML
                        Discrimination</a></p>
                <p>Finally, you report should include a recommendation if you want to use the ML, scrap it, or make
                    specific improvements before rolling it out. Specifically your report should include the following
                    information:</p>
                <ul>
                    <li>
                        <p>Data-driven analysis of the predictions the model is making.</p>
                    <li>
                        <p>Any concerns you have about the quality of the predictions in light of this data.</p>
                    <li>
                        <p>Any features in the data you are concerned about from a fairness perspective. HINT: you might
                            want to consult your last homework when considering this.</p>
                    <li>
                        <p>A data-driven analysis of the interplay between these features and your ML model. There are
                            various ways to do this, but a simple approach might consider the following:</p>
                        <ul>
                            <li>
                                <p>Distribution of this feature in your dataset.</p>
                            <li>
                                <p>Distribution of this feature in your accepted and rejected recommendation populations
                                </p>
                            <li>
                                <p>Relationship between this feature and your false positives and false negatives.</p>
                        </ul>
                    <li>
                        <p>Based on this data, you should consider what is the fairness strategy that you are trying to
                            achieve. You may use one of the fairness strategies we considered in class, or define your
                            own. If you define a new fairness strategy, you should describe it, and present why you
                            think it is a better fit than any of the existing strategies for this product.</p>
                    <li>
                        <p>If you are not happy with the performance of the system, based on the data you have
                            collected, you should do the following:</p>
                        <ul>
                            <li>
                                <p>Report on what aspects of the system you are unhappy with</p>
                            <li>
                                <p>Iterate your model 1 iteration, and see if you can improve its performance. Most
                                    likely, this will NOT be enough to fix it, but your goal in this assignment is to
                                    learn enough to make a reasonable estimate of the effort needed to fix the model.
                                </p>
                            <li>
                                <p>Make an estimate of how long it will take to bring the model up to acceptable
                                    performance. This can be a “T-Shirt” estimate (e.g., S/M/L/XL) but it should also
                                    include completion criteria. This will look like specific thresholds that your model
                                    should achieve before you would be comfortable shipping it as a part of your
                                    product.</p>
                        </ul>
                    <li>
                        <p>At the end of this report, make a recommendation to your CTO. This recommendation should be
                            one of the following:</p>
                        <ul>
                            <li>
                                <p>It is good enough to use now, we should ship it.</p>
                            <li>
                                <p>It is not good enough to ship, but we have a plan to improve it</p>
                            <li>
                                <p>We don’t feel comfortable shipping this feature, we should scrap it.</p>
                        </ul>
                </ul>
                <h3 id="deadlines-and-deliverables"> <a href="#deadlines-and-deliverables" class="anchor-heading"
                        aria-labelledby="deadlines-and-deliverables"><svg viewBox="0 0 16 16" aria-hidden="true">
                            <use xlink:href="#svg-link"></use>
                        </svg></a> Deadlines and Deliverables</h3>
                <p>This homework has one (1) deadline and two (2) deliverables. The deadline (<strong>Tuesday,</strong>
                    <strong>Nov 23rd</strong>) is for all the deliverables: the static analysis design doc, and the
                    report on the ML model.</p>
                <p><strong>Part A: Static Analysis - Group (due Nov 23) - 100 points (50%)</strong></p>
                <p>The deliverable for this part is a Design Document/RFC that provides (1) a justified explanation for
                    which tool(s) you think the project should use moving forward, and (2) how it shall be integrated
                    into your process (you must recommend at least one tool, even if it’s with reservations). This
                    latter point should address both technical (e.g., at what point in the development/deployment
                    process shall it be integrated? What sorts of customization or configuration will you be using?) and
                    social issues (e.g., how will you incentivize the change?), as applicable. The justification should
                    be based on your experiences running the tools and, as much as possible, be grounded in data about,
                    for example, tool usability, output, and customizability.</p>
                <p>Be sure the RFC also explains/justifies the alternative tools (or process options, if pertinent) that
                    have been rejected. To receive full credit, you must consider at least N total tool options in your
                    RFC, where N is the size of your team.</p>
                <p>The document should also contain other relevant sections for a Design Document/RFC for this type of
                    (development process) feature. Are there open questions? Issues you consider out of scope? Drawbacks
                    of the proposed process/tooling that you are accepting for some (good) reason? Etc. That is: make
                    sure it’s a good/complete design document!</p>
                <p><strong>NOTE: in your PDF submitted to gradescope, you should explictly reference at least one commit
                        on which your tool has been run in your repo.</strong></p>
                <p>Submit the Design Document as a single PDF to Gradescope.</p>
                <p><strong>Part B: ML Explainability – Group (due Nov 23) – 100 points (50%)</strong></p>
                <p>For this deliverable, you will be collecting data, and writing a report. The report should include
                    the data you collect as well as your interpretation of the data.</p>
                <p>First, you should collect data by running LIME on your ML model from the last homework (use the model
                    you have in the fall-2021-hw4 repository), with the new data. You should present the results of this
                    as data in your report.</p>
                <p>Then, you will interpret the data to explain why your machine learning model is making predictions.
                    This information should include the features that provide the most predictive power.</p>
                <p>You should also evaluate your machine learning model considering fairness issues. You will evaluate
                    the performance of your model with a specific target fairness strategy in mind, and if you are
                    unhappy with the fairness of the model, you will come up with thresholds that you feel the model
                    must meet before you would feel comfortable using it.</p>
                <p>Based on your findings, you should recommend one of three options. You might feel that the Model is
                    good enough to deploy as is, you might recommend specific changes before you deploy, or you might
                    recommend it not be deployed at all.</p>
                <p>Submit this report as a PDF via Gradescope.</p>
                <hr>
                <footer>
                    <p class="text-small text-grey-dk-100 mb-0">this website is based on
                        https://github.com/kevinlin1/just-the-class</p>
                </footer>
            </div>
        </div>
        <div class="search-overlay"></div>
    </div>