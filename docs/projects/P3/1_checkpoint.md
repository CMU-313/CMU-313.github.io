# Project 3A: Deployment and CI

## Deliverables

**Deployment & CI** – 35 points – due Thursday, March 12, 2026, 11:59PM

- [Deployed Application (25 pts)](#deployed-application-25-pts)
- [Tools Checkpoint (10 pts)](#tools-checkpoint-10-pts)

### Deployed Application (25 pts)

Your team will be using Linux Virtual Machines (VMs) hosted at CMU for the deployment of the NodeBB application. Further instructions on how to deploy can be found on the [NodeBB Deployment on Linux VM](deployment.md) page.

Once you have successfully deployed your website, make sure to test within your team to ensure that your added feature(s) from Project 2 are properly integrated.

By the checkpoint deadline, you should as a group:

- Submit the link to the deployed site onto Gradescope
- Add the link to the deployed site and the link to the UserGuide.md that your team submitted for Project 2 to this [public spreadsheet](https://docs.google.com/spreadsheets/d/1Xmaqmu5MITPjy1TFDpohQFwzaPYcUNVviuc4jLDXPEY/edit?usp=sharing) next to your team name. This will be used in [Feature Review](/projects/p3/2_finalsubmission/#extra-credit-feature-review-6-pts) for extra credit.

### Tools Checkpoint (10 pts - 4pts for Group, 6pts for Individual)

Before jumping into tool integration, your manager would like you to research what existing analysis tools are out there that can be used with NodeBB. You will evaluate the tools, and eventually document your findings for your final deliverable.

First, identify and experiment with **at least N potential static and dynamic analysis tools** that are applicable to your system, where N is the number of people in your team (so one per person). We provide a [starter list of tools](resources.md), but you are not limited to these tools.

In your selection of tools, you should

- have **at least one** static analysis tool
- have **at least one** dynamic analysis tool
- have **at least one** tool that is not from our starter list
- **not use** any of the existing tools within NodeBB as part of your analysis (mocha/ESLint/TSLint)

Every person on the team should do the following for one of the N tools:

1. Create a separate testing branch in the team's repository (named appropriately for the tool you’re testing) to integrate the tool into your project and test out its capabilities.

2. Create a pull request to the main branch from each of these testing branches. The PR should include:

   - **Concrete evidence that you have successfully installed the tool**, through trackable file changes demonstrating that extra files/NPM packages were installed.
   - **Artifacts that demonstrate that you have successfully run the tool on your repository.** Acceptable artifacts include output files generated by the tool, or a text file containing the terminal output from the tool. You may also attach screenshots as additional pieces of evidence. These can be attached to the Pull Request in either the description or follow-up comments.
   - **Assessment of the pros/cons of your tool in the PR description.** In your evaluation, consider and experiment with the types of customization that are appropriate or necessary for this tool, both a priori (before it can be used in your project) and over time. Assess the strengths and weaknesses of your tool/technique, both quantitatively and qualitatively, with supporting evidence.

!!! note "Grading Note"
    We will not be grading the quality or quantity of any code you put into these testing branches/PRs, just the evidence that you have successfully installed and run the tool.

!!! info "Tool Evaluation"
    There are a lot of different factors to consider when evaluating a tool. We recommend discussing with your teammates and deciding on a group of metrics to focus on when performing evaluations.

!!! note "Time Management"
    Don't spend too long for this checkpoint. Set deadlines within your team to ensure that you have enough time for both the design document and integration deliverables described below for the final deadline.

By the checkpoint deadline, you will each individually submit to Gradescope:

- A link to the **PR that demonstrates that you have successfully installed and run your chosen tool**, including artifacts that act as appropriate evidence as outlined above. Your **PR description** should contain a pro/con analysis of the tool that answers the questions above with supporting evidence. This will be worth 6 out of the 10 points. 

You will also as a group submit to Gradescope:

- Links to all N PRs. This will be worth 4 out of the 10 points. 

## Grading

To receive full credit for the checkpoint, we expect:

- [ ] A link to your successfully deployed web application for your team repository
- [ ] A link to your pull request for your selected tool containing evidence of the tool being run at least once on your repository. Your team's selected tools must satisfy all the following criteria:
  - Contain at least one static analysis tool
  - Contain at least one dynamic analysis tool
  - Contain at least one tool not on our starter list of tools
  - Contain no overlaps between teammates
- [ ] Your pull request description must contain an assessment of the pros/cons of your tool
